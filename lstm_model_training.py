import pandas as pdimport matplotlib.pyplot as pltimport numpy as npimport mathfrom configuration_file import configuration_varfrom configuration_file import folder_locationsfrom keras.models import Sequentialfrom keras.layers import Densefrom keras.layers import LSTMfrom keras.layers import Dropoutfrom sklearn.preprocessing import MinMaxScalerfrom sklearn.metrics import mean_squared_errorimport amazon_serviceimport lstm_service#Downloading the datadf = amazon_service.get_csv_data_from_amazon('EURUSD=X30m')df.columns = ['Date', 'Open', 'High', 'Low', 'Close']#Preparing the datax = df.filter(['Open', 'High', 'Low'])y = df.filter(['Close'])#Data Normalizationx = lstm_service.normalize_data(x)y = lstm_service.normalize_data(y)#Preparing samplesx_samples, y_samples = lstm_service.prepare_samples(x, y)#Splitting data into training set and testing setx_samples_train, y_samples_train, x_samples_test, y_samples_test = lstm_service.split_into_training_and_testing_set(x_samples, y_samples)#LSTM Modelmodel = Sequential([    LSTM(units=60, return_sequences=True, input_shape=(x_samples_train.shape[1],x_samples_train.shape[2])),    Dropout(0.23),    LSTM(units=60, return_sequences=True),    Dropout(0.22),    LSTM(units=60, return_sequences=True),    Dropout(0.23),    LSTM(units=60),    Dropout(0.21),    Dense(units=1)    ])history = lstm_service.model_compiling_and_saving(model, x_samples_train, y_samples_train, 10, 64)#Plotting the dataplt.plot(history.history['loss'])plt.title('model train vs validation loss')plt.ylabel('loss')plt.xlabel('epoch')plt.legend(['train', 'validation'], loc='upper right')plt.show()